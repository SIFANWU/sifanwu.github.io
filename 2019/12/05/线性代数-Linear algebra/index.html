<!DOCTYPE html>


  <html class="light page-post">


<head>
  <meta charset="utf-8">
  
  <title>线性代数-Linear algebra | JimWu&#39;s Blog</title>

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
    <meta name="keywords" content="DeepLearning,MachineLearning,Python,JAVa,Python" />
  

  <meta name="description" content="线性代数 Linear algebra向量 vector1. 向量的L1范数和L2范数的区分：  L0范数：向量中非0元素的个数. L1范数：向量中各个元素绝对值之和. L2范数：向量中各元素的平方和再开平方根.  2. 各中范数的优缺点对比：  L1范数可以进行特征选择，让部分特征系数变成0,即具有稀疏性. L2范数可以防止过拟合，提高模型的泛化能力. L1会趋向于产生少量的特征，使大部分特征系">
<meta name="keywords" content="Daily life">
<meta property="og:type" content="article">
<meta property="og:title" content="线性代数-Linear algebra">
<meta property="og:url" content="https:&#x2F;&#x2F;github.com&#x2F;SIFANWU&#x2F;sifanwu.github.io&#x2F;2019&#x2F;12&#x2F;05&#x2F;%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0-Linear%20algebra&#x2F;index.html">
<meta property="og:site_name" content="JimWu&#39;s Blog">
<meta property="og:description" content="线性代数 Linear algebra向量 vector1. 向量的L1范数和L2范数的区分：  L0范数：向量中非0元素的个数. L1范数：向量中各个元素绝对值之和. L2范数：向量中各元素的平方和再开平方根.  2. 各中范数的优缺点对比：  L1范数可以进行特征选择，让部分特征系数变成0,即具有稀疏性. L2范数可以防止过拟合，提高模型的泛化能力. L1会趋向于产生少量的特征，使大部分特征系">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https:&#x2F;&#x2F;www.zhihu.com&#x2F;equation?tex&#x3D;x&#x3D;%5Bx_1,x_2,x_3,%5Ccdots,x_n%5D%5E%7BT%7D%5C%5C">
<meta property="og:image" content="https:&#x2F;&#x2F;www.zhihu.com&#x2F;equation?tex&#x3D;%7C%7Cx%7C%7C_p&#x3D;(%7Cx_1%7C%5Ep+%7Cx_2%7C%5Ep+%7Cx_3%7C%5Ep+%5Ccdots+%7Cx_n%7C%5Ep)%5E%7B%5Cfrac%7B1%7D%7Bp%7D%7D%5C%5C">
<meta property="og:image" content="https:&#x2F;&#x2F;www.zhihu.com&#x2F;equation?tex&#x3D;%7C%7Cx%7C%7C_1%20&#x3D;%7Cx_1%7C%20+%20%7Cx_2%7C%20+%7Cx_3%7C%20+%20%5Ccdots%20+%7Cx_n%7C%5C%5C">
<meta property="og:image" content="https:&#x2F;&#x2F;www.zhihu.com&#x2F;equation?tex&#x3D;%7C%7Cx%7C%7C_2%20&#x3D;(%7Cx_1%7C%5E2%20+%20%7Cx_2%7C%5E2%20+%7Cx_3%7C%5E2%20+%20%5Ccdots%20+%20%7Cx_n%7C%5E2)%5E%7B%5Cfrac%7B1%7D%7B2%7D%7D%5C%5C">
<meta property="og:image" content="http:&#x2F;&#x2F;latex.codecogs.com&#x2F;gif.latex?n*n%7D">
<meta property="og:image" content="http:&#x2F;&#x2F;latex.codecogs.com&#x2F;gif.latex?tr(A)">
<meta property="og:image" content="http:&#x2F;&#x2F;latex.codecogs.com&#x2F;gif.latex?A%20&#x3D;(a_%7Bi,j%7D)_%7Bm*n%7D">
<meta property="og:image" content="http:&#x2F;&#x2F;latex.codecogs.com&#x2F;gif.latex?tr(A)&#x3D;%5Csum_i%20a_%7Bi,i%7D">
<meta property="og:image" content="http:&#x2F;&#x2F;latex.codecogs.com&#x2F;gif.latex?%7C%7CA%7C%7C_F&#x3D;%5Csqrt%7Btr(AA%5ET)%7D">
<meta property="og:image" content="http:&#x2F;&#x2F;latex.codecogs.com&#x2F;gif.latex?tr(A)&#x3D;tr(A%5ET)">
<meta property="og:image" content="http:&#x2F;&#x2F;latex.codecogs.com&#x2F;gif.latex?A%5Cin%7BR%5E%7Bm*n%7D%7D,B%5Cin%7BR%5E%7Bn*m%7D%7D">
<meta property="og:image" content="http:&#x2F;&#x2F;latex.codecogs.com&#x2F;gif.latex?tr(AB)&#x3D;tr(BA)">
<meta property="og:image" content="http:&#x2F;&#x2F;latex.codecogs.com&#x2F;gif.latex?tr(ABC)&#x3D;tr(CAB)&#x3D;tr(BCA)">
<meta property="og:image" content="http:&#x2F;&#x2F;latex.codecogs.com&#x2F;gif.latex?A&#x3D;(a_%7Bi,j%7D)%5Cin%7BR%5E%7Bm*n%7D%7D,B&#x3D;(b_%7Bi,j%7D)%5Cin%7BR%5E%7Bm*n%7D%7D">
<meta property="og:image" content="http:&#x2F;&#x2F;latex.codecogs.com&#x2F;gif.latex?A%5Ccirc%7BB%7D&#x3D;%20%5Cleft%5B%5Cbegin%7Bmatrix%7D%20a_%7B1,1%7Db_%7B1,1%7D%20%20&amp;%20a_%7B1,2%7Db_%7B1,2%7D%20%20&amp;%20%5Ccdots%20&amp;a_%7B1,n%7Db_%7B1,n%7D%20%5C%5C%20a_%7B2,1%7Db_%7B2,1%7D%20%20&amp;%20a_%7B2,2%7Db_%7B2,2%7D%20%20&amp;%20%5Ccdots%20&amp;a_%7B2,n%7Db_%7B2,n%7D%20%5C%5C%20%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%20a_%7Bm,1%7Db_%7Bm,1%7D%20%20&amp;%20a_%7Bm,2%7Db_%7Bm,2%7D%20%20%20&amp;%20%5Ccdots%20&amp;a_%7Bm,n%7Db_%7Bm,n%7D%20%5C%20%5Cend%7Bmatrix%7D%20%5Cright%5D">
<meta property="og:image" content="http:&#x2F;&#x2F;latex.codecogs.com&#x2F;gif.latex?A%20%5Cotimes%20B%20&#x3D;%20%5Cleft%5B%20%5Cbegin%7Bmatrix%7D%20a_%7B1,1%7DB%20%20&amp;%20a_%7B1,2%7DB%20%20&amp;%20%5Ccdots%20&amp;a_%7B1,n%7DB%20%20%5C%5C%20a_%7B2,1%7DB%20%20&amp;%20a_%7B2,2%7DB%20%20&amp;%20%5Ccdots%20&amp;a_%7B2,n%7DB%20%20%5C%5C%20%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%20a_%7Bm,1%7DB%20&amp;%20a_%7Bm,2%7DB%20%20%20&amp;%20%5Ccdots%20&amp;a_%7Bm,n%7DB%20%5C%20%5Cend%7Bmatrix%7D%20%5Cright%5D">
<meta property="og:image" content="http:&#x2F;&#x2F;latex.codecogs.com&#x2F;gif.latex?%5Cfrac%7B%5Cpartial%7Bu%7D%7D%7B%5Cpartial%7Bv%7D%7D">
<meta property="og:image" content="http:&#x2F;&#x2F;latex.codecogs.com&#x2F;gif.latex?%5Cfrac%7B%5Cpartial%7Bu%7D%7D%7B%5Cpartial%7B%5Cvec%7Bv%7D%7D%7D&#x3D;(%5Cfrac%7B%5Cpartial%7Bu%7D%7D%7B%5Cpartial%7Bv_1%7D%7D,%20%5Cfrac%7B%5Cpartial%7Bu%7D%7D%7B%5Cpartial%7Bv_2%7D%7D,%5Ccdots,%5Cfrac%7B%5Cpartial%7Bu%7D%7D%7B%5Cpartial%7Bv_n%7D%7D)%5ET">
<meta property="og:image" content="http:&#x2F;&#x2F;latex.codecogs.com&#x2F;gif.latex?%5Cfrac%7B%5Cpartial%20u%7D%7B%5Cpartial%20V%7D%20&#x3D;%20%5Cleft%5B%20%5Cbegin%7Bmatrix%7D%20%5Cfrac%7B%5Cpartial%20u%7D%7B%5Cpartial%20V_%7B1,1%7D%7D%20%20&amp;%20%5Cfrac%7B%5Cpartial%20u%7D%7B%5Cpartial%20V_%7B1,2%7D%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cfrac%7B%5Cpartial%20u%7D%7B%5Cpartial%20V_%7B1,n%7D%7D%20%5C%5C%20%5Cfrac%7B%5Cpartial%20u%7D%7B%5Cpartial%20V_%7B2,1%7D%7D%20%20&amp;%20%5Cfrac%7B%5Cpartial%20u%7D%7B%5Cpartial%20V_%7B2,2%7D%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cfrac%7B%5Cpartial%20u%7D%7B%5Cpartial%20V_%7B2,n%7D%7D%20%5C%5C%20%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%20%5Cfrac%7B%5Cpartial%20u%7D%7B%5Cpartial%20V_%7Bm,1%7D%7D%20%20&amp;%20%5Cfrac%7B%5Cpartial%20u%7D%7B%5Cpartial%20V_%7Bm,2%7D%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cfrac%7B%5Cpartial%20u%7D%7B%5Cpartial%20V_%7Bm,n%7D%7D%20%5C%20%5Cend%7Bmatrix%7D%20%5Cright%5D">
<meta property="og:image" content="http:&#x2F;&#x2F;latex.codecogs.com&#x2F;gif.latex?%5Cfrac%7B%5Cpartial%20%5Cvec%7Bu%7D%7D%7B%5Cpartial%20v%7D&#x3D;(%5Cfrac%7B%5Cpartial%20u_1%7D%7B%5Cpartial%20v%7D,%20%5Cfrac%7B%5Cpartial%20u_2%7D%7B%5Cpartial%20v%7D,%20%5Ccdots,%5Cfrac%7B%5Cpartial%20u_n%7D%7B%5Cpartial%20v%7D)%5ET">
<meta property="og:image" content="http:&#x2F;&#x2F;latex.codecogs.com&#x2F;gif.latex?%5Cfrac%7B%5Cpartial%20%5Cvec%7Bu%7D%7D%7B%5Cpartial%20%5Cvec%7Bv%7D%7D%20&#x3D;%20%5Cleft%5B%20%5Cbegin%7Bmatrix%7D%20%5Cfrac%7B%5Cpartial%20u_1%7D%7B%5Cpartial%20V_1%20%7D%20%20&amp;%20%5Cfrac%7B%5Cpartial%20u_1%7D%7B%5Cpartial%20V_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cfrac%7B%5Cpartial%20u_1%7D%7B%5Cpartial%20V_n%20%7D%20%5C%5C%20%5Cfrac%7B%5Cpartial%20u_2%7D%7B%5Cpartial%20V_1%20%7D%20%20&amp;%20%5Cfrac%7B%5Cpartial%20u_2%7D%7B%5Cpartial%20V_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cfrac%7B%5Cpartial%20u_2%7D%7B%5Cpartial%20V_n%20%7D%20%5C%5C%20%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%20%5Cfrac%7B%5Cpartial%20u_m%7D%7B%5Cpartial%20V_1%20%7D%20%20&amp;%20%5Cfrac%7B%5Cpartial%20u_m%7D%7B%5Cpartial%20V_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cfrac%7B%5Cpartial%20u_m%7D%7B%5Cpartial%20V_n%20%7D%20%5C%20%5Cend%7Bmatrix%7D%20%5Cright%5D">
<meta property="og:image" content="http:&#x2F;&#x2F;latex.codecogs.com&#x2F;gif.latex?%5Cfrac%7B%5Cpartial%20U%7D%7B%5Cpartial%20v%7D%20&#x3D;%20%5Cleft%5B%20%5Cbegin%7Bmatrix%7D%20%5Cfrac%7B%5Cpartial%20U_%7B1,1%7D%7D%7B%5Cpartial%20v%7D%20%20&amp;%20%5Cfrac%7B%5Cpartial%20U_%7B1,2%7D%7D%7B%5Cpartial%20v%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cfrac%7B%5Cpartial%20U_%7B1,n%7D%7D%7B%5Cpartial%20v%20%7D%20%5C%5C%20%5Cfrac%7B%5Cpartial%20U_%7B2,1%7D%7D%7B%5Cpartial%20v%7D%20%20&amp;%20%5Cfrac%7B%5Cpartial%20U_%7B2,2%7D%7D%7B%5Cpartial%20v%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cfrac%7B%5Cpartial%20U_%7B2,n%7D%7D%7B%5Cpartial%20v%20%7D%20%5C%5C%20%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%20%5Cfrac%7B%5Cpartial%20U_%7Bm,1%7D%7D%7B%5Cpartial%20v%7D%20%20&amp;%20%5Cfrac%7B%5Cpartial%20U_%7Bm,2%7D%7D%7B%5Cpartial%20v%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cfrac%7B%5Cpartial%20U_%7Bm,n%7D%7D%7B%5Cpartial%20v%20%7D%20%5C%20%5Cend%7Bmatrix%7D%20%5Cright%5D">
<meta property="og:updated_time" content="2019-12-11T11:47:45.801Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;www.zhihu.com&#x2F;equation?tex&#x3D;x&#x3D;%5Bx_1,x_2,x_3,%5Ccdots,x_n%5D%5E%7BT%7D%5C%5C">

  

  
    <link rel="icon" href="/favicon.ico">
  

  <link href="/css/styles.css?v=c114cbeddx" rel="stylesheet">


  
    <link rel="stylesheet" href="/css/personal-style.css">
  

  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-38189205-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


  
  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?57e94d016e201fba3603a8a2b0263af0";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>


  
  <script type="text/javascript">
	(function(){
	    var bp = document.createElement('script');
	    var curProtocol = window.location.protocol.split(':')[0];
	    if (curProtocol === 'https') {
	        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
	    }
	    else {
	        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
	    }
	    var s = document.getElementsByTagName("script")[0];
	    s.parentNode.insertBefore(bp, s);
	})();
  </script>



  
    <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css">
  

</head>

<body>


  
    <span id="toolbox-mobile" class="toolbox-mobile">Home</span>
  

  <div class="post-header CENTER">
   
  <div class="toolbox">
    <a class="toolbox-entry" href="/">
      <span class="toolbox-entry-text">Home</span>
      <i class="icon-angle-down"></i>
      <i class="icon-home"></i>
    </a>
    <ul class="list-toolbox">
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/archives/"
            rel="noopener noreferrer"
            target="_self"
            >
            博客
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/category/"
            rel="noopener noreferrer"
            target="_self"
            >
            分类
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/tag/"
            rel="noopener noreferrer"
            target="_self"
            >
            标签
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/about/"
            rel="noopener noreferrer"
            target="_blank"
            >
            关于
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/search/"
            rel="noopener noreferrer"
            target="_self"
            >
            搜索
          </a>
        </li>
      
    </ul>
  </div>


</div>


  <div id="toc" class="toc-article">
    <strong class="toc-title">文章目录</strong>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#线性代数-Linear-algebra"><span class="toc-text">线性代数 Linear algebra</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#向量-vector"><span class="toc-text">向量 vector</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#总结：L1会趋向于产生少量的特征，而其他的特征都是0，而L2会选择更多的特征，这些特征都会接近于0。"><span class="toc-text">总结：L1会趋向于产生少量的特征，而其他的特征都是0，而L2会选择更多的特征，这些特征都会接近于0。</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#矩阵-matrix"><span class="toc-text">矩阵 matrix</span></a></li></ol></li></ol>
  </div>



<div class="content content-post CENTER">
   <article id="post-线性代数-Linear algebra" class="article article-type-post" itemprop="blogPost">
  <header class="article-header">
    <h1 class="post-title">线性代数-Linear algebra</h1>

    <div class="article-meta">
      <span>
        <i class="icon-calendar"></i>
        <span>2019.12.05</span>
      </span>

      
        <span class="article-author">
          <i class="icon-user"></i>
          <span>JimWU</span>
        </span>
      

      


      

      
      <i class="fa fa-eye"></i> 
        <span id="busuanzi_container_page_pv">
           &nbsp热度 <span id="busuanzi_value_page_pv">
           <i class="fa fa-spinner fa-spin"></i></span>℃
        </span>
      
      
    </div>
  </header>

  <div class="article-content">
    
      <h1 id="线性代数-Linear-algebra"><a href="#线性代数-Linear-algebra" class="headerlink" title="线性代数 Linear algebra"></a>线性代数 Linear algebra</h1><h2 id="向量-vector"><a href="#向量-vector" class="headerlink" title="向量 vector"></a>向量 vector</h2><p><strong>1. 向量的L1范数和L2范数的区分：</strong></p>
<ul>
<li>L0范数：向量中非0元素的个数.</li>
<li>L1范数：向量中各个元素绝对值之和.</li>
<li>L2范数：向量中各元素的平方和再开平方根.</li>
</ul>
<p><strong>2. 各中范数的优缺点对比：</strong></p>
<ul>
<li>L1范数可以进行特征选择，让部分特征系数变成0,即具有稀疏性.</li>
<li>L2范数可以防止过拟合，提高模型的泛化能力.</li>
<li>L1会趋向于产生少量的特征，使大部分特征系数变成0；L2会选择更多地特征，这些特征都会接近0（即 系数非常小）。</li>
</ul>
<p><strong>概念的直观理解：</strong><br>范数是具有“长度”概念的函数。在向量空间内，为所有的向量都赋予了非零的增长度或者大小。不同的范数，所求的长度或者大小是不同的。</p>
<p>For Example: 二维空间中，向量（3，4）的长度是5，那么5就是这个向量的范数的值，更确切的说，是欧式范数或者L2范数的值。</p>
<blockquote>
<p>公式理解：对于$P-$范数，如果 </p>
<p><img src="https://www.zhihu.com/equation?tex=x=%5Bx_1,x_2,x_3,%5Ccdots,x_n%5D%5E%7BT%7D%5C%5C" alt="">    </p>
<p>那么向量x的$P-$范数就是:</p>
<p><img src="https://www.zhihu.com/equation?tex=%7C%7Cx%7C%7C_p=(%7Cx_1%7C%5Ep+%7Cx_2%7C%5Ep+%7Cx_3%7C%5Ep+%5Ccdots+%7Cx_n%7C%5Ep)%5E%7B%5Cfrac%7B1%7D%7Bp%7D%7D%5C%5C" alt=""> </p>
<p>L1范数：</p>
<p><img src="https://www.zhihu.com/equation?tex=%7C%7Cx%7C%7C_1%20=%7Cx_1%7C%20+%20%7Cx_2%7C%20+%7Cx_3%7C%20+%20%5Ccdots%20+%7Cx_n%7C%5C%5C" alt=""></p>
<p>L2范数：</p>
<p><img src="https://www.zhihu.com/equation?tex=%7C%7Cx%7C%7C_2%20=(%7Cx_1%7C%5E2%20+%20%7Cx_2%7C%5E2%20+%7Cx_3%7C%5E2%20+%20%5Ccdots%20+%20%7Cx_n%7C%5E2)%5E%7B%5Cfrac%7B1%7D%7B2%7D%7D%5C%5C" alt=""></p>
</blockquote>
<p><em>特别的，L0范数：指向量中非零元素的个数。无穷范数：指向量中所有元素的最大绝对值。</em></p>
<p><strong>深度理解：</strong><br>一般来说，监督学习可以看做优化两个目标函数：</p>
<ol>
<li>损失函数（Loss function）- 实际数值与预测数值的差距.<ul>
<li>对于Loss函数，如果是Square loss，那就是最小二乘了；如果是Hinge Loss，那就是著名的SVM了；如果是exp-Loss，那就是牛逼的 Boosting了；如果是log-Loss，那就是Logistic Regression了；不同的loss函数，具有不同的拟合特性。</li>
</ul>
</li>
<li>规则化函数 即正则项 -不仅要保证训练误差值最小，更希望模型的测试误差小，对参数矩阵W的规则化函数去约束模型，使之尽量的简单。<ul>
<li>规则化函数Ω(w)也有很多种选择，一般是模型复杂度的单调递增函数，模型越复杂，规则化值就越大。比如，规则化项可以是模型参数向量的范数。然而，不同的选择对参数w的约束不同，取得的效果也不同，但我们在论文中常见的都聚集在：零范数、一范数、二范数、迹范数、Frobenius范数和核范数等等。</li>
</ul>
</li>
<li>L0范数是指向量中非0的元素的个数。如果我们用L0范数来规则化一个参数矩阵W的话，就是希望W的大部分元素都是0，即具有稀疏功能。<ul>
<li>为什么不用L0范数？<ul>
<li>个人理解：一是因为L0范数很难优化求解（NP难问题），二是L1范数是L0范数的最优凸近似，而且它比L0范数要容易优化求解。总结：L1范数和L0范数可以实现稀疏，L1因具有比L0更好的优化求解特性而被广泛应用。</li>
<li>参数稀疏的好处：<ul>
<li>特征选择(Feature Selection)：将非主要信息特征权重置为0可以避免这些信息对测试集样本预测结果的干扰，相当于特征的自动选择或者过滤。</li>
<li>可解释性(Interpretability)：只选出主要影响的特征，便于分析影响预测的结果的主要因素，比如 1000维参数，只有5个才是决定是否正确的特征，则只要这5个特征预测准确即可。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>L2范数为何更受欢迎？L2范数可以避免过拟合的发生。优化L2范数的规则项||w||<sup>2</sup>，使之值最小，可以使参数矩阵||w||中每个值都很小，接近于0，但是不等于0（此处于L0范数的区别），这样使模型越简单，越简单的模型越不容易产生过拟合现象。<ul>
<li>为什么参数越小，模型越简单？<ul>
<li>个人理解：1.参数数值越小，对模型预测结果的影响就越小。只有权重系数较大的特征对模型的预测结果影响较大。2.参数值越小，实际上限制了多项式分量的影响，相当于变相减少了参数的个数，所以模型变得简单。</li>
</ul>
</li>
</ul>
</li>
</ol>
<h5 id="总结：L1会趋向于产生少量的特征，而其他的特征都是0，而L2会选择更多的特征，这些特征都会接近于0。"><a href="#总结：L1会趋向于产生少量的特征，而其他的特征都是0，而L2会选择更多的特征，这些特征都会接近于0。" class="headerlink" title="总结：L1会趋向于产生少量的特征，而其他的特征都是0，而L2会选择更多的特征，这些特征都会接近于0。"></a>总结：L1会趋向于产生少量的特征，而其他的特征都是0，而L2会选择更多的特征，这些特征都会接近于0。</h5><hr>
<h2 id="矩阵-matrix"><a href="#矩阵-matrix" class="headerlink" title="矩阵 matrix"></a>矩阵 matrix</h2><blockquote>
<p>在线性代数中，一个<img src="http://latex.codecogs.com/gif.latex?n*n%7D" alt=""> 矩阵A的对角线(从左上方至右下方的对角线)上各个元素的总和被称为矩阵A的迹，一般记作<img src="http://latex.codecogs.com/gif.latex?tr(A)" alt="">.</p>
</blockquote>
<blockquote>
<p>数学表达：设矩阵 <img src="http://latex.codecogs.com/gif.latex?A%20=(a_%7Bi,j%7D)_%7Bm*n%7D" alt=""> ,则A的迹为: <img src="http://latex.codecogs.com/gif.latex?tr(A)=%5Csum_i%20a_%7Bi,i%7D" alt="">.</p>
</blockquote>
<p>迹的性质有：</p>
<ul>
<li>迹是所有对角线元素的和</li>
<li>迹是所有特征值的和</li>
<li>A的F范数等于$AA^T$的迹的平方根：<img src="http://latex.codecogs.com/gif.latex?%7C%7CA%7C%7C_F=%5Csqrt%7Btr(AA%5ET)%7D" alt=""> </li>
<li>A的迹等于$A^T$的迹：<img src="http://latex.codecogs.com/gif.latex?tr(A)=tr(A%5ET)" alt=""></li>
<li>交换律：假设 <img src="http://latex.codecogs.com/gif.latex?A%5Cin%7BR%5E%7Bm*n%7D%7D,B%5Cin%7BR%5E%7Bn*m%7D%7D" alt="">, 则有：<img src="http://latex.codecogs.com/gif.latex?tr(AB)=tr(BA)" alt=""> </li>
<li>结合律：<img src="http://latex.codecogs.com/gif.latex?tr(ABC)=tr(CAB)=tr(BCA)" alt=""></li>
</ul>
<p><strong>矩阵的运算</strong></p>
<blockquote>
<p>给定两个矩阵<img src="http://latex.codecogs.com/gif.latex?A=(a_%7Bi,j%7D)%5Cin%7BR%5E%7Bm*n%7D%7D,B=(b_%7Bi,j%7D)%5Cin%7BR%5E%7Bm*n%7D%7D" alt="">,定义：  </p>
<ul>
<li><p>阿达马积 <code>Hadamard product</code>(又称作逐元素积)：<br><img src="http://latex.codecogs.com/gif.latex?A%5Ccirc%7BB%7D=%20%5Cleft%5B%5Cbegin%7Bmatrix%7D%20a_%7B1,1%7Db_%7B1,1%7D%20%20&%20a_%7B1,2%7Db_%7B1,2%7D%20%20&%20%5Ccdots%20&a_%7B1,n%7Db_%7B1,n%7D%20%5C%5C%20a_%7B2,1%7Db_%7B2,1%7D%20%20&%20a_%7B2,2%7Db_%7B2,2%7D%20%20&%20%5Ccdots%20&a_%7B2,n%7Db_%7B2,n%7D%20%5C%5C%20%5Cvdots%20&%20%5Cvdots%20&%20%5Cddots%20&%20%5Cvdots%20%5C%5C%20a_%7Bm,1%7Db_%7Bm,1%7D%20%20&%20a_%7Bm,2%7Db_%7Bm,2%7D%20%20%20&%20%5Ccdots%20&a_%7Bm,n%7Db_%7Bm,n%7D%20%5C%20%5Cend%7Bmatrix%7D%20%5Cright%5D" alt=""></p>
</li>
<li><p>克罗内积 <code>Kronnecker product</code>:<br><img src="http://latex.codecogs.com/gif.latex?A%20%5Cotimes%20B%20=%20%5Cleft%5B%20%5Cbegin%7Bmatrix%7D%20a_%7B1,1%7DB%20%20&%20a_%7B1,2%7DB%20%20&%20%5Ccdots%20&a_%7B1,n%7DB%20%20%5C%5C%20a_%7B2,1%7DB%20%20&%20a_%7B2,2%7DB%20%20&%20%5Ccdots%20&a_%7B2,n%7DB%20%20%5C%5C%20%5Cvdots%20&%20%5Cvdots%20&%20%5Cddots%20&%20%5Cvdots%20%5C%5C%20a_%7Bm,1%7DB%20&%20a_%7Bm,2%7DB%20%20%20&%20%5Ccdots%20&a_%7Bm,n%7DB%20%5C%20%5Cend%7Bmatrix%7D%20%5Cright%5D" alt=""></p>
</li>
<li><p>各种类型的偏导数:</p>
<ul>
<li>标量对标量的偏导数：<img src="http://latex.codecogs.com/gif.latex?%5Cfrac%7B%5Cpartial%7Bu%7D%7D%7B%5Cpartial%7Bv%7D%7D" alt=""></li>
<li>标量对向量(n维向量)的偏导数: </li>
</ul>
</li>
</ul>
<p><img src="http://latex.codecogs.com/gif.latex?%5Cfrac%7B%5Cpartial%7Bu%7D%7D%7B%5Cpartial%7B%5Cvec%7Bv%7D%7D%7D=(%5Cfrac%7B%5Cpartial%7Bu%7D%7D%7B%5Cpartial%7Bv_1%7D%7D,%20%5Cfrac%7B%5Cpartial%7Bu%7D%7D%7B%5Cpartial%7Bv_2%7D%7D,%5Ccdots,%5Cfrac%7B%5Cpartial%7Bu%7D%7D%7B%5Cpartial%7Bv_n%7D%7D)%5ET" alt=""></p>
<ul>
<li>标量对矩阵($m*n$阶矩阵)的偏导数：</li>
</ul>
<p><img src="http://latex.codecogs.com/gif.latex?%5Cfrac%7B%5Cpartial%20u%7D%7B%5Cpartial%20V%7D%20=%20%5Cleft%5B%20%5Cbegin%7Bmatrix%7D%20%5Cfrac%7B%5Cpartial%20u%7D%7B%5Cpartial%20V_%7B1,1%7D%7D%20%20&%20%5Cfrac%7B%5Cpartial%20u%7D%7B%5Cpartial%20V_%7B1,2%7D%7D%20&%20%5Ccdots%20&%20%5Cfrac%7B%5Cpartial%20u%7D%7B%5Cpartial%20V_%7B1,n%7D%7D%20%5C%5C%20%5Cfrac%7B%5Cpartial%20u%7D%7B%5Cpartial%20V_%7B2,1%7D%7D%20%20&%20%5Cfrac%7B%5Cpartial%20u%7D%7B%5Cpartial%20V_%7B2,2%7D%7D%20&%20%5Ccdots%20&%20%5Cfrac%7B%5Cpartial%20u%7D%7B%5Cpartial%20V_%7B2,n%7D%7D%20%5C%5C%20%5Cvdots%20&%20%5Cvdots%20&%20%5Cddots%20&%20%5Cvdots%20%5C%5C%20%5Cfrac%7B%5Cpartial%20u%7D%7B%5Cpartial%20V_%7Bm,1%7D%7D%20%20&%20%5Cfrac%7B%5Cpartial%20u%7D%7B%5Cpartial%20V_%7Bm,2%7D%7D%20&%20%5Ccdots%20&%20%5Cfrac%7B%5Cpartial%20u%7D%7B%5Cpartial%20V_%7Bm,n%7D%7D%20%5C%20%5Cend%7Bmatrix%7D%20%5Cright%5D" alt=""></p>
<ul>
<li>向量(m维向量)对标量的偏导数：</li>
</ul>
<p><img src="http://latex.codecogs.com/gif.latex?%5Cfrac%7B%5Cpartial%20%5Cvec%7Bu%7D%7D%7B%5Cpartial%20v%7D=(%5Cfrac%7B%5Cpartial%20u_1%7D%7B%5Cpartial%20v%7D,%20%5Cfrac%7B%5Cpartial%20u_2%7D%7B%5Cpartial%20v%7D,%20%5Ccdots,%5Cfrac%7B%5Cpartial%20u_n%7D%7B%5Cpartial%20v%7D)%5ET" alt=""></p>
<ul>
<li>向量(m维向量)对向量(n维向量)的偏导数(雅可比矩阵，行优先)</li>
</ul>
<p><img src="http://latex.codecogs.com/gif.latex?%5Cfrac%7B%5Cpartial%20%5Cvec%7Bu%7D%7D%7B%5Cpartial%20%5Cvec%7Bv%7D%7D%20=%20%5Cleft%5B%20%5Cbegin%7Bmatrix%7D%20%5Cfrac%7B%5Cpartial%20u_1%7D%7B%5Cpartial%20V_1%20%7D%20%20&%20%5Cfrac%7B%5Cpartial%20u_1%7D%7B%5Cpartial%20V_2%7D%20&%20%5Ccdots%20&%20%5Cfrac%7B%5Cpartial%20u_1%7D%7B%5Cpartial%20V_n%20%7D%20%5C%5C%20%5Cfrac%7B%5Cpartial%20u_2%7D%7B%5Cpartial%20V_1%20%7D%20%20&%20%5Cfrac%7B%5Cpartial%20u_2%7D%7B%5Cpartial%20V_2%7D%20&%20%5Ccdots%20&%20%5Cfrac%7B%5Cpartial%20u_2%7D%7B%5Cpartial%20V_n%20%7D%20%5C%5C%20%5Cvdots%20&%20%5Cvdots%20&%20%5Cddots%20&%20%5Cvdots%20%5C%5C%20%5Cfrac%7B%5Cpartial%20u_m%7D%7B%5Cpartial%20V_1%20%7D%20%20&%20%5Cfrac%7B%5Cpartial%20u_m%7D%7B%5Cpartial%20V_2%7D%20&%20%5Ccdots%20&%20%5Cfrac%7B%5Cpartial%20u_m%7D%7B%5Cpartial%20V_n%20%7D%20%5C%20%5Cend%7Bmatrix%7D%20%5Cright%5D" alt=""></p>
<blockquote>
<blockquote>
<p>如果为列优先，则为上面矩阵的转置。    </p>
</blockquote>
</blockquote>
<ul>
<li>矩阵($m*n$阶矩阵)对标量的偏导数</li>
</ul>
<p><img src="http://latex.codecogs.com/gif.latex?%5Cfrac%7B%5Cpartial%20U%7D%7B%5Cpartial%20v%7D%20=%20%5Cleft%5B%20%5Cbegin%7Bmatrix%7D%20%5Cfrac%7B%5Cpartial%20U_%7B1,1%7D%7D%7B%5Cpartial%20v%7D%20%20&%20%5Cfrac%7B%5Cpartial%20U_%7B1,2%7D%7D%7B%5Cpartial%20v%7D%20&%20%5Ccdots%20&%20%5Cfrac%7B%5Cpartial%20U_%7B1,n%7D%7D%7B%5Cpartial%20v%20%7D%20%5C%5C%20%5Cfrac%7B%5Cpartial%20U_%7B2,1%7D%7D%7B%5Cpartial%20v%7D%20%20&%20%5Cfrac%7B%5Cpartial%20U_%7B2,2%7D%7D%7B%5Cpartial%20v%7D%20&%20%5Ccdots%20&%20%5Cfrac%7B%5Cpartial%20U_%7B2,n%7D%7D%7B%5Cpartial%20v%20%7D%20%5C%5C%20%5Cvdots%20&%20%5Cvdots%20&%20%5Cddots%20&%20%5Cvdots%20%5C%5C%20%5Cfrac%7B%5Cpartial%20U_%7Bm,1%7D%7D%7B%5Cpartial%20v%7D%20%20&%20%5Cfrac%7B%5Cpartial%20U_%7Bm,2%7D%7D%7B%5Cpartial%20v%7D%20&%20%5Ccdots%20&%20%5Cfrac%7B%5Cpartial%20U_%7Bm,n%7D%7D%7B%5Cpartial%20v%20%7D%20%5C%20%5Cend%7Bmatrix%7D%20%5Cright%5D" alt=""></p>
</blockquote>
<hr>

    
  </div>

</article>


   

   
  <div class="box-prev-next clearfix">
    <a class="hide pull-left" href="/">
        <i class="icon icon-angle-left"></i>
    </a>
    <a class="hide pull-right" href="/">
        <i class="icon icon-angle-right"></i>
    </a>
  </div>




</div>


  <a id="backTop" class="back-top">
    <i class="icon-angle-up"></i>
  </a>




  <div class="modal" id="modal">
  <span id="cover" class="cover hide"></span>
  <div id="modal-dialog" class="modal-dialog hide-dialog">
    <div class="modal-header">
      <span id="close" class="btn-close">关闭</span>
    </div>
    <hr>
    <div class="modal-body">
      <ul class="list-toolbox">
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/archives/"
              rel="noopener noreferrer"
              target="_self"
              >
              博客
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/category/"
              rel="noopener noreferrer"
              target="_self"
              >
              分类
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/tag/"
              rel="noopener noreferrer"
              target="_self"
              >
              标签
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/about/"
              rel="noopener noreferrer"
              target="_blank"
              >
              关于
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/search/"
              rel="noopener noreferrer"
              target="_self"
              >
              搜索
            </a>
          </li>
        
      </ul>

    </div>
  </div>
</div>



  
      <div class="fexo-comments comments-post">
    

    

    
    

    

    
    

    

  </div>

  

  <script type="text/javascript">
  function loadScript(url, callback) {
    var script = document.createElement('script')
    script.type = 'text/javascript';

    if (script.readyState) { //IE
      script.onreadystatechange = function() {
        if (script.readyState == 'loaded' ||
          script.readyState == 'complete') {
          script.onreadystatechange = null;
          callback();
        }
      };
    } else { //Others
      script.onload = function() {
        callback();
      };
    }

    script.src = url;
    document.getElementsByTagName('head')[0].appendChild(script);
  }

  window.onload = function() {
    loadScript('/js/bundle.js?235683', function() {
      // load success
    });
  }
</script>

</body>
</html>
